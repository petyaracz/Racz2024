## ADD TRIANGLES

---
title: "Baseline learners"
author: "Rácz, Péter"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, error = FALSE, message = FALSE, fig.path = 'figures/', fig.width = 8, fig.height = 4)
knitr::opts_knit$set(root.dir = '~/Github/Racz2024') # !!!

# source('~/Github/Racz2024/models/learner/baseline/baseline_learner_helper.R')

library(tidyverse)
library(magrittr)
library(glue)

library(patchwork)
library(gghalves)
library(ggthemes)

library(lme4)
library(knitr)

# -- fun -- #

cloudPlot = function(dat,a,b){
  dat %>% 
  filter(!is.na({{a}})) %>% 
  ggplot(aes({{a}},{{b}})) +
  geom_half_violin(side = 'r', alpha = .5) +
  geom_half_boxplot(side = 'r', width = .1) +
  geom_half_point(side = 'l', width = .5, size = .5, range_scale = .5) +
  xlab('derivational suffix') +
  ylab('log odds') +
  theme_bw() +
  coord_flip()
}

# -- data -- #

## base

lakok = read_tsv('~/Github/Racz2024/resource/real_words/ik_verbs/ikes_pairs_webcorpus2.tsv')
cselekszenek = read_tsv('~/Github/Racz2024/resource/real_words/epenthetic_stems/epenthesis_pairs_webcorpus2.tsv')
hotelban = read_tsv('~/Github/Racz2024/resource/real_words/front_harmony/fh_pairs_webcorpus2.tsv')
cselekszenek_plus = read_tsv('~/Github/Racz2024/resource/real_words/epenthetic_stems/epenthesis_reference_webcorpus2.tsv')
hotelban_plus = read_tsv('~/Github/Racz2024/resource/real_words/noun_bag.tsv')
plus = read_tsv('~/Github/Racz2024/resource/real_words/plus_bag.tsv')

h = read_tsv('~/Github/Racz2024/resource/hu_list.txt') %>% 
  pull(word)

v = read_tsv('~/Github/Racz2024/resource/real_words/verb_bag.tsv')
b = read_tsv('~/Github/Racz2024/exp_data/baseline/baseline_tidy_proc.tsv')
# get triangles in here

## gcm pred

lakok_gcm = read_tsv('~/Github/Racz2024/models/learner/baseline/pred_gcm/lakok_gcm_baseline_pred.tsv')
cselekszenek_gcm = read_tsv('~/Github/Racz2024/models/learner/baseline/pred_gcm/cselekszenek_gcm_baseline_pred.tsv')
hotelban_gcm = read_tsv('~/Github/Racz2024/models/learner/baseline/pred_gcm/hotelban_gcm_baseline_pred.tsv')

## mgl pred

lakok_mgl_rules = read_tsv('~/Github/Racz2024/models/learner/baseline/pred_mgl/lakok_mgl_rules.tsv')
cselekszenek_mgl_rules = read_tsv('~/Github/Racz2024/models/learner/baseline/pred_mgl/cselekszenek_mgl_rules.tsv')
hotelban_mgl_rules = read_tsv('~/Github/Racz2024/models/learner/baseline/pred_mgl/hotelban_mgl_rules.tsv')

lakok_mgl = read_tsv('~/Github/Racz2024/models/learner/baseline/pred_mgl/lakok_mgl_baseline.tsv')
cselekszenek_mgl = read_tsv('~/Github/Racz2024/models/learner/baseline/pred_mgl/cselekszenek_mgl_baseline.tsv')
hotelban_mgl = read_tsv('~/Github/Racz2024/models/learner/baseline/pred_mgl/hotelban_mgl_baseline.tsv')

# -- wrangling -- #

dik = bind_rows(lakok,cselekszenek)
ik = filter(v, str_detect(lemma, 'ik$'))
hotelban %<>% filter(base %in% h) # full of silly words 
hotelban_plus %<>% 
  filter(lemma %in% h) %>%  # full of silly words
  mutate(category = 
           case_when(
             vh == 'front' ~ 'hotelben', 
             vh == 'back' ~ 'hotelban'
             )
         )
```

# Background

A lot of early work in language modelling focussed on regular/irregular variation in the English past tense. This is because the English past tense exhibits both rule-like behaviour (there is a regular rule that applies to the vast majority of form) and analogical behaviour (irregular forms that look similar also behave in a similar way) and because people working on the problem all spoke English.

The English past tense is an unusual example of variation in inflectional morphology, for three reasons. The irregular patterns have very little productivity. There is a wide array of disparate irregular patterns that result from diachronic accidents and do not interact with each other or other parts of the grammar. (Variation in the past tense of irregular forms is social or stylistic but not contextual.) Language user awareness of the pattern is low and  usually restricted to specific forms.

Here I look at three inflectional patterns in Hungarian, a language with complex morphology. These patterns exhibit different properties (from the English past tense and one another). I used the Hungarian Webcorpus to build training sets that exhibit variable behaviour. I built test sets based on a forced-choice elicitation experiment using nonce forms. I then went on to implement a range of learning models using the training sets to see how well they predict human responses in the test set.

The learning models were GCM, MGL, fasttext, huBERT (Google's Bert fit on Hungarian Wikipedia and web crawl) (https://huggingface.co/SZTAKI-HLT/hubert-base-cc), and Puli-GPT-3 (EleutherAi's GPT-Neox-3 fit on Hungarian Wikipedia and web crawl) (https://huggingface.co/NYTK/PULI-GPT-3SX).

# The inflectional patterns

Two patterns relate to verbal conjugation, one to nominal declension. One can apply to all verbs in its category, two have phonological restrictions. One is a social marker, the other two are largely under the radar. One is expressed for a specific function only, the other two across a range of functions.

```{r }
# this is from Readme_build_nonce_words.md : ^^
```

1. lakok/lakom

The definite form is used in the indefinite in certain 1sg.present verbs in educated colloquial Hungarian. These verbs all end in `-ik` which is originally a reflexive suffix ("fésül" comb.3sg.indef, "fésülök" comb.1sg.indef, "fésülködik" comb.refl.3sg.indef, "fésülködök/fésülködöm" comb.refl.1sg.indef).

More prevalent with some noun-to-verb derivational suffixes (-odik, -zik, -lik). See Rácz 2019. Note that Hungarian verbs is a closed class.

This variation only applies in the 1sg.indef. It has no phonological restrictions. It can apply to all `-ik` verbs. It applies productively to neologisms formed using derivational suffixes that end in `-ik` (e.g. "gugli.zik" google.3sg.indef, "guglizok/guglizom"). The `-m` variant is a marker of educated, careful speech. 

2. hotelban/hotelben

Nominal post-positions usually agree with stem in front/back vowel and vowel roundedness. There are front and back stem vowels. Some stem vowels (i,í,e,é) are neutral. (e) and increasingly (é) are front vowels. As a result, back vowel + (e,é) stems can vary. See https://doi.org/10.3765/amp.v8i0.4750 (Gloss: "hotelban" hotel.in)

This variation applies in a wide range of nominal declensions -- anywhere where the suffix shows front-back variation. Its rate of use is also sensitive to the suffix. It applies productively to borrowings ("spandexnak" spandex.dat).

3. cselekszik/cselekedik

A Hungarian verb stem can end in CC or CVC. Verbal suffixes can be C- or V-initial. Some stems vary in that a CVC stem is realised with a C-initial suffix and a CC stem is realised with a V-initial suffix. This is likely because we have a CVCV sequence in the former case and a VCCV sequence in the latter case, both of which are phonotactically well-formed (Some verbs always have CVC stems even when this is not phonotactically necessary, other verbs are defective, only have CC stems and some C-initial suffixed forms do not exist.)

Some epenthetic stems are monomorphemic (fürdik, ugrik: ugrani - ugornak - ugranak) but most are formed with a small set of productive derivational suffixes. (Gloss: "cselekszik" act.3sg.indef, "ugrik" jump.3sg.indef)

This variation applies in a wide range of verbal inflections -- anywhere where the suffix is consonant-initial. Its rate of use is sensitive to the suffix. It garners very little sociolinguistic attention, apart from some lexicalised forms, such as "emlékszik" remember.3sg.indef / "emlékezik" commemorate.3sg.indef.

# Creating the training sets using the Hungarian Webcorpus

I used the morphologically disambiguated and pos tagged Hungarian Webcorpus 2 (https://hlt.bme.hu/en/resources/webcorpus2) to compile a form frequency list. I used this list to calculate the log odds of variation in the (i) definite/indefinite suffix used in 1sg.indef -ik verb forms, (ii) the front/back suffix used with variable noun stems, and (iii) CVC/CC forms of variable verb+suffix combinations.

For the lakok/lakom 1sg.indef -ik verb forms, there is, in practice, only one variable morphological exponent (whether the 1sg.indef form is realised with the indefinite or the definite suffix). For the hotelban/hotelben variable noun stems, I selected five locative nominal post-positions known to vary: the inessive, the illative, the adessive, the dative, and the sublative. For the cselekszik/cselekedik variable verb stems, I selected five verbal suffixes known to vary: the infinitive, the Pres.NDef.3Pl, the Past.NDef.3Pl, the Cond.NDef.3Sg, and the Pres.NDef.2Pl.

For the nouns, variation does not affect the stem itself, and so identifying variable stems with the five post-positions was straightforward. For the verbs, instead of searching for a list of possibly variable lemmata, each possible CC and CVC variant was built and then grepped individually to make sure the scoop was as large as possible.

All three variable patterns are strongly correlated with cross-referenced sets from the first Hungarian Webcorpus (http://mokk.bme.hu/en/resources/webcorpus/). 

The three patterns show structured variation in the resulting dataset. To give one example, the two verbal patterns are sensitive to the type of derivational suffix on the verb stem:

```{r plot_deriv_suffix_corpus_v}
cloudPlot(dik, derivational, log_odds) +
  ggtitle('Corpus variation is sensitive to stem-final derivational suffix') +
  scale_y_continuous(name = 'log odds',  sec.axis = sec_axis( trans = ~ plogis(.), name="prob", breaks = round(plogis(c(-5,-2,-1,0,1,2,5)),2))) +
  facet_wrap( ~ variation)

```

The noun pattern is sensitive to the stem-final vowel:

```{r plot_deriv_suffix_corpus_n}
cloudPlot(hotelban, vowel, log_odds) +
  ggtitle('Corpus variation is sensitive to final stem vowel') +
  scale_y_continuous(name = 'log odds',  sec.axis = sec_axis( trans = ~ plogis(.), name="prob", breaks = round(plogis(c(-5,-2,-1,0,1,2,5)),2))) +
  xlab('stem vowel') +
  facet_wrap( ~ variation)
```

# Creating the test sets

## Generating nonce words

An ngram model was built to generate nonce words from pre-defined constituent parts in relevant real word patterns. Nouns were generated based on existing bisyllabic variable noun stems (where a back vowel is followed by e/é). Verbs were generated based on existing bi- and trisyllabic verb stems ending in one of four productive derivational verbal suffixes: -lik, -odik, -szik, -zik. The verb class is closed in Hungarian and new verbs are formed using derivational suffixes: Google - Guglizik, Facebook - Facebookol, etc. Native speakers are far more likely to accept nonce verbs that have recognisable derivational endings.

Existing words were broken up into onset-rhyme couplets and then these were freely recombined to build nonce forms. For verbs, I added some complex onsets to enlarge the set of possible combinations. The recombined set was filtered to make sure it (a) excludes uncommon constituents (e.g. "yiddish" is a Hungarian word but most Hungarian words do not have a "y-" onset) and (b) observes restrictions on syllables and consonant sequences in monomorphemic forms. Most of these restrictions were only relevant for the nouns. If a participant takes the phonotactic cues to parse a nonce noun as a compound, they will be very likely to only consider the second constituent in selecting a suffix (so that all suffixes will be front-only). For verbs, the derivational suffixes constitute a morphemic boundary. 

Nonce forms were sampled across relevant dimensions (nouns: is the second vowel e/é; -ik verbs: number of syllables, epenthetic verbs: number of syllables and type of derivational suffix) and then the sampled lists were filtered to make sure (a) they had sufficient edit distance from existing forms and (b) did not start or end with a string identical to an existing word and (c) had sufficient edit distance from one another. Final samples were hand-filtered.

## Generating final forms

The final sets consisted of 162 forms per variation type (noun / -ik verb / epenethetic verb). All nouns in the hotelban/hotelben set were bisyllabic, consisting of a back vowel and front e/é. All verbs in the lakok/lakom set were mono- or bisyllabic and ended in -lik (see 'csuklik'), -szik (see 'emlékszik'), or -zik (see 'éhezik'). All verbs in the cselekszik/cselekedik set were mono- or bisyllabic and had one of three alterations: -lik / -ozik (see porlik/porozik, common for loans, see squashol / squashozik), -szik / -dik (see cselekszik/cselekedik), or -zik / -zik (see habzik / habozik).

For the hotelban/hotelben and cselekszik/cselekedik patterns, a suffix was chosen at random for each form. For the lakok/lakom pattern, variation was restricted to one suffix, so this filtering was not necessary.

## The baseline experiment

The prompt / target couplets were inserted into simple carrier sentences, following Berko’s WUG paradigm (Berko 1958).

85 students of the Budapest University of Technology and Economics took up the task for course credit in the spring of 2022, 78 finished it (67 women, median age 22). The study was approved by the United Ethical Review Committee for Research in Psychology in Hungary (EPKEB, ref.\ number 2021-119).

The task was coded in Psychopy (Peirce et al. 2019). Each participant completed the task on their home computer via Pavlovia, an online experimental platform (https://pavlovia.org/). Each participant responded to 162 written prompts with a written binary forced-choice response: 54 for lakok/lakom, 54 for cselekszenek/cselekdnek, 54 for hotelban/hotelben. Participants were instructed that they would see Hungarian words, which might not be familiar to them, and would have to pick a suitable form in the target sentence for the word in the prompt sentence. They were given an example before starting. 

Each prompt received a median 27 responses (25th = 26, 75th = 29), for a total of 13284 responses by 78 participants to 486 prompts.

The three sets display structured variation in the test set. This is similar to the variation seen in the training set. This is the plot of log odds across derivational endings in the responses for the verb prompts:

```{r plot_deriv_suffix_response_v}
b %>% 
  filter(variation != 'hotelban/hotelben') %>% 
  cloudPlot(derivational, log_odds) +
    ggtitle('Response variation is sensitive to stem-final derivational suffix') +
    scale_y_continuous(name = 'log odds',  sec.axis = sec_axis( trans = ~ plogis(.), name="prob", breaks = round(plogis(c(-5,-2,-1,0,1,2,5)),2))) +
    facet_wrap( ~ variation)

```

```{r plot_deriv_suffix_response_n}
b %>% 
  filter(variation == 'hotelban/hotelben') %>% 
  cloudPlot(vowel, log_odds) +
    ggtitle('Corpus variation is sensitive to final stem vowel') +
    scale_y_continuous(name = 'log odds',  sec.axis = sec_axis( trans = ~ plogis(.), name="prob", breaks = round(plogis(c(-5,-2,-1,0,1,2,5)),2))) +
    xlab('stem vowel') +
    facet_wrap( ~ variation)
```

## The Generalised Context Model

The generalised context model takes an individual target form and a set of categories. It then calculates the distance of the target form to the training forms in the categories and comes up with a distance to each category. Distance is based on edit distance between forms, with no internal representation for sound segments. In the present case, the number of categories is always 2 and the distances sum up to 1, where distance to category 1 equals 1 - distance to category 2.

_Training sets_

For lakok/lakom, all `-ik` verbs are able to show variation. When a verb has no variable forms in the corpus, this is probably because I or somebody else filtered them out at some point or the corpus is too small. But it's better to restrict the training set to attested variable forms.

```{r lakok_c_dens}
# one pair for one verb

lakok %>% 
  ggplot(aes(log_odds)) +
  geom_density() +
  geom_vline(xintercept = median(lakok$log_odds)) +
  theme_bw() +
  ggtitle('Corpus density of log lakok/lakom')

```

For cselekszenek/cselekednek, there is a set number of stems that are either CVC or CC and some of them vary between the two.

```{r cseleksz_c_dens}
fit1 = glmer(cbind(freq_1,freq_2) ~ 1 + (1|base_tr) + (1|xpostag), family = binomial, data = cselekszenek)

cselekszenek_base = ranef(fit1) %>% 
  as_tibble() %>% 
  select(grp,condval) %>% 
  rename('base_tr' = grp, 'intercept' = condval)

count(cselekszenek_plus,category) %>% 
  add_row(category = 'cvc/cc', n = nrow(cselekszenek_base)) %>% 
  kable('simple')

cselekszenek_base %>% 
  ggplot(aes(intercept)) +
  geom_density() +
  geom_vline(xintercept = median(cselekszenek_base$intercept)) +
  theme_bw() +
  ggtitle('Corpus Density of log cselekszenek/cselekednek via stem intercept')

```

For hotelban/hotelben, there is a set number of stems that always select front suffixes, a set that always select back suffixes, and a variable set. This is similar to the cselekszenek/cselekednek set. (For the sake of simplicity, we exclude forms that end in a transparent vowel).

```{r hotelban_c_dens}
fit2 = glmer(cbind(freq_1,freq_2) ~ 1 + (1|base_tr) + (1|xpostag), family = binomial, data = hotelban)

hotelban_base = ranef(fit2) %>% 
  as_tibble() %>% 
  select(grp,condval) %>% 
  rename('base_tr' = grp, 'intercept' = condval)

count(hotelban_plus,category) %>%
  filter(!is.na(category)) %>% # sámli etc., we skip these
  add_row(category = 'hotelban/hotelben', n = nrow(hotelban_base)) %>% 
  kable('simple')

hotelban_base %>% 
  ggplot(aes(intercept)) +
  geom_density() +
  geom_vline(xintercept = median(cselekszenek_base$intercept)) +
  theme_bw() +
  ggtitle('Corpus Density of log hotelban/hotelben via stem intercept')

```

For lakok/lakom, I split the variable set at the median. For cselekszenek/cselekednek, I have three sets: the variable set, split at the median, stable CVC and CC forms only, combination of variable and stable forms. For hotelban/hotelben, I have three training sets: the variable set, split at the median, stable front and back forms only, combination of variable and stable forms.

_Test sets_

The test data are the responses from the experiment. These are aggregated and split down the median as well.

```{r resp_dens}
b %>% 
  ggplot(aes(log_odds)) +
  geom_density() +
  theme_bw() +
  facet_wrap( ~ variation) +
  ggtitle('Response density of log a/b')

```

_Fitting the model_

The GCM has two parameters, s (0-1) and p (0/1). It's worthwhile to search for s.

```{r gcm_eval}
lakok_gcm_s = pull(distinct(lakok_gcm,s))
cselekszenek_gcm_s = pull(distinct(cselekszenek_gcm,s))
hotelban_gcm_s = pull(distinct(hotelban_gcm,s))
```

_Results_

I calculate accuracy by taking the GCM category weight for category 1 for each test form, comparing it with the log odds of category 1 / category 2 responses in the baseline data, and calculating R^2.

The accuracy of the best model is `r unique(round(lakok_gcm$r2,2))` for lakok/lakom, based on a training set of variable only forms, with an s of `r lakok_gcm_s`. It is `r unique(round(cselekszenek_gcm$r2,2))` for cselekszenek/cselekednek, based on a training set of `r unique(cselekszenek_gcm$training_set)` forms, with an s of `r cselekszenek_gcm_s`. It is `r unique(round(hotelban_gcm$r2,2))` for hotelban/hotelben, based on a training set of `r unique(hotelban_gcm$training_set)` forms, with an s of `r hotelban_gcm_s`.  

_Discussion_

Prediction accuracy is fine for lakok/lakom, terrible for cselekszenek/cselekednek, and very good for hotelban/hotelben. There are two readings for this. First, participants compare the test forms to existing forms in a way that is similar to what the GCM does. So, for the noun forms, similarity is a very strong predictor of category membership. Verb forms look more similar to one another, and so the similarity effect drops for lakok/lakom and even more so for cselekszenek/cselekednek, where variation might be more strongly affected by other factors, such as semiotic readings that people might attribute to the verb endings or the patterns of the specific verbal conjugational suffixes.

Second, the test forms look a lot like real forms, and participants assume that they will behave the way similar real forms will. This works really well for nouns, but much less for verbs, which look more like one another.

## The Minimal Generalisation Learner

The MGL takes input-output pairs and looks for regularities in the input and the output. This way, it discovers rules that derive the output from the input. Rules operate on specific contexts in outputs. Rules have a scope of inputs that contain these context and hits, a subset of the scope, where the requirements of the rule's application are met and the rule actually applies. The ratio of hits over scope is the rule's reliability. Reliability scales with the size of the scope. This is called confidence. A rule has the same reliability if it applies to 1 form from a scope of 10 forms or to 100 forms from a scope of 1000. But our confidence in the second rule is stronger.

The MGL was fit with its default settings and only using edit distance between inputs as well as outputs.

_Training sets_

The training sets were the same as for the GCM. The difference is that (a) the MGL doesn't take forms and category weights (such as form: "eszik"; category: "lakom"). Instead, it takes an input form, an output form, and a grammatical category (such as input: "eszik"; output: "eszem"; grammar: "1sg.indef"). This is straightforward in the lakok/lakom category, where every training and test form had the same grammatical category, 1sg.indef.

For cselekszenek/cselekednek and hotelben/hotelban, each category was split across the verbal/nominal suffixes contained in the training data. 

_Test sets_

The test sets were the same as for the GCM.

_Fitting the model_

The MGL does not start with preset output variants for the test forms. Instead, it formulates rules based on the training data and then applies these rules to the test data. After training the model on the training data, I selected rule 1, the rule that generates form 1 and rule 2, the rule that generates form 2 and calculated an adjusted confidence score that is the confidence for rule 1 divided by the summed confidence of rule 1 and rule 2. 

If the GCM did not generate a rule for form 1, this adjusted confidence will be 0. If the GCM did not generate a rule for form 2, this adjusted confidence will be 1. If it didn't generate a rule for either forms, the adjusted confidence of the form is not interpretable.

```{r mgl_eval}
rules_missing_cs = cselekszenek_mgl_rules %>% 
  filter(is.na(rule)) %>% 
  count(training_type,variant_number)

rules_missing_h = hotelban_mgl_rules %>% 
  filter(is.na(rule)) %>% 
  count(training_type,variant_number)

hotelban_mgl_preds = hotelban_mgl %>% 
  group_by(training_type) %>% 
  summarise(cor = cor(adjusted_confidence,log_odds)) %>% 
  filter(cor == max(cor))

```

_Results_

For the lakok/lakom set, the results were straightforward. The MGL generated a rule for all variable forms in the test set. The R^2 of the adjusted confidence values and the log odds of the responses in the baseline experiment is `r round(cor(lakok_mgl$adjusted_confidence,lakok_mgl$log_odds),2)`, which is higher than the accuracy of the GCM. This is based on only `r nrow(distinct(lakok_mgl_rules,rule))` rules, instead of the individual comparisons made for every target item by the GCM.

For the cselekszenek/cselekednek set, the MGL never finds a rule for the CVC variant, irrespective of whether it is trained on variable forms only, variable and stable CVC/CC forms, or stable forms only. For the vast majority of target forms, it never finds the CC variant either, except when trained on variable and stable forms. Taken together, this means that the MGL provides no interpretable predictions for participant behaviour in the baseline experiment for the cselekszenek/cselekednek set.

For the hotelben/hotelban set, the model generated a rule for all variable forms in the test set. The accuracy of the predictions was best when trained on variable forms only (unlike the GCM) and even then, it was only `r round(hotelban_mgl_preds$cor,2)`.

_Discussion_

For lakok/lakom, variable behaviour is largely determined by what the verb looks like, and the MGL is able to latch onto this. For cselekszenek/cselekednek, the type of variation we are looking for is at least partly driven by phonotactic restrictions: if the suffix is vowel-initial, the stem vowel should be surpressed. If the suffix is consonant-initial, some consonant pairings can not surface, requiring a CVC form, others have to surface, requiring a CC form, with a fair amount of variation in between. This logic is hard to find and the MGL doesn't find it. For hotelben/hotelban, the pattern is likely dependant on both vowel-tier and consonant-tier effects that are separate from each other. Since the MGL looks for patterns on a single tier, it likely cannot detect these patterns very effectively.